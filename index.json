[{"content":"hugo搭建博客 hugo准备 安装 # mac os brew install hugo # ubuntu sudo apt-get install hugo 新建site hugo new site my_blog_site 指定主题 拉取主题文件到site目录下的themes文件夹内（在此展示使用submodule的对比） cd my_blog_site # 拉取ananke主题 git init git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke.git themes/ananke # 拉取papermode主题 git clone https://github.com/adityatelange/hugo-PaperMod themes/PaperMod --depth=1 在配置中指明使用的主题(可以下载多个主题文件，在配置中指定哪个生效) echo theme = \\\u0026#34;ananke\\\u0026#34; \u0026gt;\u0026gt; config.toml 指定内容文件 可以直接手动创建md文件，也可以使用hugo提供的如下命令创建，文件父目录代表’CATEGORY‘\nhugo new posts/my-first-post.md 本地运行 执行下方命令将会根据我们的文件在{content,data,layouts,static,themes}生成相应文件\nhugo server -D 访问http://localhost:1313/ch看效果\n编译静态网页 默认将静态网页文件生成在./public目录下\nhugo -D ","permalink":"https://examplesite.com/posts/hugo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/","summary":"使用hugo搭建博客\u0026ndash;记录搭建此博客的最初步骤","title":"搭建hugo博客"},{"content":"安装minikube 传送门：https://minikube.sigs.k8s.io/docs/start/\n(记得安装kubectl,可以自单独安装，也可以通过minikube下载kubectl)\n打开控制面板\nminikube dashboard 准备服务 服务代码 来个传统的http-server\nfunc rawHttpServer() { http.HandleFunc(\u0026#34;/hello\u0026#34;, func(w http.ResponseWriter, r *http.Request) { _, _ = w.Write([]byte(\u0026#34;hello world\u0026#34;)) }) if err := http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil); err != nil { fmt.Println(err) os.Exit(1) } } 服务编译打包 1.编写DockerFile\nFROM golang:alpine AS builder RUN mkdir /app COPY . /app WORKDIR /app/httpdemo RUN go build -o httpdemo FROM alpine:3.18.2 WORKDIR /runtime COPY --from=builder /app/httpdemo/httpdemo /runtime/httpdemo ENTRYPOINT [\u0026#34;./httpdemo\u0026#34;] 2.打包镜像 特别注意，因为选择本地打包，在打包前需要将minikube的docker环境变量设置好\n# 此命令将minikube的docker-env在当前session中设置 eval $(minikube docker-env) # 打包httpdemo:v1 docker build -t httpdemo:v1 -f httpdemo/Dockerfile . 服务部署 1.创建Deployment(启动pod)\n因为Deployment默认是会从hub上拉镜像，因此需要将imagePullPolicy配置从ifNotPresent改为Never\nkubectl create deployment http-demo --image=httpdemo:v1 --image-pull-policy=Never btw, 可以通过-o选项生成当前deployment配置文件\nkubectl create deployment http-demo --image=httpdemo:v1 -o yaml # 在生成的httpdemo.yaml中修改imagePullPolicy # 重新根据配置加载deployment kubectl apply -f httpdemo.yaml 2.创建service kubernetes默认pod只能在其虚拟内网中通信, 若要和外网通信需要建立service ```shell kubectl expose deployment http-demo --type=LoadBalancer --port=8080,8081 minikube service http-demo 3.打开页面，可以正常访问服务\n","permalink":"https://examplesite.com/posts/kubernetesminikube%E9%83%A8%E7%BD%B2%E6%9C%8D%E5%8A%A1/","summary":"使用hugo搭建博客\u0026ndash;记录搭建此博客的最初步骤","title":"kubernetes(minikube)部署服务"},{"content":"简介 ratelimit是uber提供的一个极简的漏桶限流实现，主打一个简约轻量，只提供一个接口来实现带阻塞的限流能力。\nimport \u0026#34;go.uber.org/ratelimit\u0026#34; 漏桶限流的方案，即抽象一个类似漏桶的概念，请求只能按照恒定的速率从桶中“漏”过。其实核心是控制流速，桶不桶的并不重要；从uber对此的实现也能看出，核心是把握速率即单位时间内放行的流量(请求个数)。计数限流、漏桶限流、令牌桶限流这三种方案相关的介绍已经有很多了，在此就不过多赘述了。\n源码分析 代码结构 New func New(rate int, opts ...Option) Limiter { return newAtomicInt64Based(rate, opts...) } rate即为最小单位时间通过的请求个数(即流速)；option包含三种可选配置：可指定clock实现，slack松弛区间，perOption最小时间单位 Limiter定义 type Limiter interface { // Take should block to make sure that the RPS is met. Take() time.Time } 就只定义了一个Take方法来实现限流，返回当前通过限流逻辑的时间 ratelimit内部保留了三种limiter实现: 最基础的limiter_mutexbased，改进为原子锁的limiter_atomic，简化数据结构后的limiter_atomic_int64。真正投入使用的是最后一种limiter_atomic_int64。 代码实现 感谢uber将着三种实现都保留在了此项目中，使得我们有机会从中感受到它每一次的优化了什么，背后的思考是什么。接下来让我们快速分析这三个实现版本，每个版本就一个核心方法，代码量很小，\nlimiter_mutexbased // Take calls is on average per/rate. func (t *mutexLimiter) Take() time.Time { t.Lock() defer t.Unlock() now := t.clock.Now() // 如果是第一次请求，直接放行 if t.last.IsZero() { t.last = now return t.last } // sleepFor 计算的是处理当前请求我们需要等待多长时间，其值通过单个请求的流速以及上一个请求通过的时间来决定。 t.sleepFor += t.perRequest - now.Sub(t.last) // 在一些极端场景下，我们不能允许sleepFor成为一个很大的负值，否则那将代表后续系统可能允许极高的RPS通过。（这里的t.maxSlack是个负数） if t.sleepFor \u0026lt; t.maxSlack { t.sleepFor = t.maxSlack } // 如果sleepFor是大于0的，那么我们就需要等待 if t.sleepFor \u0026gt; 0 { t.clock.Sleep(t.sleepFor) t.last = now.Add(t.sleepFor) t.sleepFor = 0 } else { t.last = now } return t.last } 源码的英文注释其实已经讲得很明白了，希望我写的中文不会反而增加了理解难度。 这里核心理解sleepFor这样一个结构就够了，逻辑其实很简单，都在注释里了。 limiter_atomic func (t *atomicLimiter) Take() time.Time { var ( newState state taken bool interval time.Duration ) // 真正互斥的操作是CompareAndSwapPointer，只有替换成功才代表处理了当前这个请求，因此外围会增加一个for循环；这个for循环内大部分逻辑都是处于并发中的。 for !taken { now := t.clock.Now() previousStatePointer := atomic.LoadPointer(\u0026amp;t.state) oldState := (*state)(previousStatePointer) newState = state{ last: now, sleepFor: oldState.sleepFor, } // 对第一次请求，直接放行(并发场景就算走进了这个分支里，咱也不知自己是不是真正的第一个请求，所以还得通过token判断) if oldState.last.IsZero() { taken = atomic.CompareAndSwapPointer(\u0026amp;t.state, previousStatePointer, unsafe.Pointer(\u0026amp;newState)) continue } // 计算需要等待的时间 newState.sleepFor += t.perRequest - now.Sub(oldState.last) // slack处理 if newState.sleepFor \u0026lt; t.maxSlack { newState.sleepFor = t.maxSlack } // sleepFor大于零则记录需要等待的时间，睡眠的时间 if newState.sleepFor \u0026gt; 0 { newState.last = newState.last.Add(newState.sleepFor) interval, newState.sleepFor = newState.sleepFor, 0 } taken = atomic.CompareAndSwapPointer(\u0026amp;t.state, previousStatePointer, unsafe.Pointer(\u0026amp;newState)) } t.clock.Sleep(interval) return newState.last } 只有CompareAndSwapPointer处才是资源互斥的，其外围都是并发场景，因此要增加for循环直到compare成功才代表处理了当前的请求哈 每次调用时，将上一次通过时间和当前等待时间(slack松弛度)作为state状态以原子锁维护。这里的每次newState.sleepFor隐含了继承上次未使用到的松弛度。 limiter_atomic_int64 func (t *atomicInt64Limiter) Take() time.Time { var ( newTimeOfNextPermissionIssue int64 now int64 ) for { now = t.clock.Now().UnixNano() timeOfNextPermissionIssue := atomic.LoadInt64(\u0026amp;t.state) switch { case timeOfNextPermissionIssue == 0 || (t.maxSlack == 0 \u0026amp;\u0026amp; now-timeOfNextPermissionIssue \u0026gt; int64(t.perRequest)): // if this is our first call or t.maxSlack == 0 we need to shrink issue time to now newTimeOfNextPermissionIssue = now case t.maxSlack \u0026gt; 0 \u0026amp;\u0026amp; now-timeOfNextPermissionIssue \u0026gt; int64(t.maxSlack): // a lot of nanoseconds passed since the last Take call // we will limit max accumulated time to maxSlack newTimeOfNextPermissionIssue = now - int64(t.maxSlack) default: // calculate the time at which our permission was issued newTimeOfNextPermissionIssue = timeOfNextPermissionIssue + int64(t.perRequest) } if atomic.CompareAndSwapInt64(\u0026amp;t.state, timeOfNextPermissionIssue, newTimeOfNextPermissionIssue) { break } } sleepDuration := time.Duration(newTimeOfNextPermissionIssue - now) if sleepDuration \u0026gt; 0 { t.clock.Sleep(sleepDuration) return time.Unix(0, newTimeOfNextPermissionIssue) } // return now if we don\u0026#39;t sleep as atomicLimiter does return time.Unix(0, now) } 不愧是最终的实现版，果然是最简洁的。首先将逻辑中的条件进行整合，直接改成switch case的方式，可谓是一目了然。 其次，保持的状态只需要简化成目标时间的时间戳就可以了，一个int64足矣，不可不谓之简约。 newTimeOfNext通过直接累加一个perRequest的方式，使得累计的slack松弛量直接保留在了newTimeOfNext和now的时间差中 总结 本库使用方面\n需要阻塞流量，且限流速率基本固定无需调整的场景，直接使用ratelimit简单又省事； maxSlack请一定要设置(或设置为WithoutSlack)，否则可能会出现极高流量击穿的场景； 代码设计方面 优化互斥逻辑，有一条大路即使用原子锁代替互斥锁。其优化的本质是减少了互斥空间内的操作，尽可能提高了并发度。而使用原子锁场景基本都是细化互斥资源到指定对象，就如此项目方案一和二之间的优化； 老生常谈的基于option的构造方法，有些对象都可以抽出来直接让使用方自己实现； 分支逻辑的优化，能抽出公共的逻辑就一定要抽出，尽可能让分支的路口和尽头都一目了然； ","permalink":"https://examplesite.com/posts/ratelimit/","summary":"ratelimit是uber提供的一个极简的漏桶限流实现，主打一个简约轻量。","title":"限流--uber-ratelimit"}]