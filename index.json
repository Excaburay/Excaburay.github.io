[{"content":"hugo搭建博客 hugo准备 安装 # mac os brew install hugo # ubuntu sudo apt-get install hugo 创建博客项目 新建site # 创建hugo项目 hugo new site my_blog_site # 初始化git仓库 cd my_blog_site \u0026amp;\u0026amp; git init 指定主题 1.拉取主题文件到site目录下的themes文件夹内（使用submodule管理子项目）\n# 拉取ananke主题 git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke.git themes/ananke # 拉取papermode主题 git submodule add --depth=1 https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod git submodule update --init --recursive # 更新某个themes(子项目) git submodule update --remote --merge 2.在配置中指明使用的主题(可以下载多个主题文件，在配置中指定哪个生效)\necho theme = \\\u0026#34;ananke\\\u0026#34; \u0026gt;\u0026gt; config.toml 指定内容文件 可以直接手动创建md文件，也可以使用hugo提供的如下命令创建，文件父目录代表’CATEGORY‘\nhugo new posts/my-first-post.md 引用图片 hugo默认会将static文件夹中的资源文件挂载到最终服务的更目录上，可将文章图片保存在static上，在文中使用绝对路径引用。如果有使用图墙服务则当我没说。\n编译静态网页 默认将静态网页文件生成在./public目录下，执行此命令将只编译静态网页\nhugo -D 本地运行 执行下方命令将会根据我们的文件在{content,data,layouts,static,themes}生成相应文件，并本地启动一个 可实时服务预览效果的服务，访问http://localhost:1313/\nhugo server -D github pages配置 域名备案流程多少比较花时间，因此可以直接将博客部署到github给每个帐号提供的github pages服务上。\ngithub.io仓库 github pages托管的静态项目，需要创建专门的github.io仓库来放置。\n创建项目名称以\u0026lt;username.github.io\u0026gt;格式命名 必须选择公开项目 建议勾选添加README文件 将hugo项目编译的public文件夹中的静态网页文件push到此仓库中，github即可将此静态网页托管至对应的github.io域名上。 github-CI/CD配置 现在，我们的博客实际依赖了两个项目，包含一个原生文件的hugo项目以及一个用来渲染页面的github pages项目。 任何的更新操作都需要涉及这两个仓库的更新：修改markdown文件-\u0026gt;hugo编译静态文件-\u0026gt;更新github pages项目-\u0026gt;网页更新\n因此，为了能够方便地更新文章，我们需要将编译和发布流程变得更加便捷更加自动化。\ngithub actions action是github支持的是一套持续集成和持续交付 (CI/CD) 平台，可用于自动执行生成、测试和部署管道。 在项目中新建.github/workflows工作流目录，定义博客编译+部署的事件以及作业。\nname: deploy run-name: ${{ github.actor }} is building out his hugo blog 🚀 on: workflow_dispatch: push: paths-ignore: - \u0026#39;.github/**\u0026#39; # workflow_dispatch: # schedule: # # Runs everyday at 8:00 AM # - cron: \u0026#34;0 0 * * *\u0026#34; jobs: build: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v3 with: submodules: true fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#34;latest\u0026#34; - name: Build Web run: hugo - name: Deploy Web uses: peaceiris/actions-gh-pages@v3 with: PERSONAL_TOKEN: ${{ secrets.PERSONAL_TOKEN }} EXTERNAL_REPOSITORY: Excaburay/Excaburay.github.io PUBLISH_BRANCH: master PUBLISH_DIR: ./public commit_message: ${{ github.event.head_commit.message }} 如上我们定义了一个deploy工作流，其中包含一个build作业 工作流触发的事件我们选择为push操作 一个作业总包含了多个操作，通过Build Web操作(执行hugo命令)来编译最新静态文件 通过Deploy Web操作，来完成新静态文件的部署 至此，每次更新我们的hugo博客项目时，只需要在更改后执行push操作，博客就可以完成自动更新。\n开始为自己的博客丰富内容吧！\n","permalink":"https://excaburay.github.io/posts/hugo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/","summary":"使用hugo搭建博客\u0026ndash;记录搭建此博客的最初步骤","title":"搭建hugo博客"},{"content":"安装minikube 传送门：https://minikube.sigs.k8s.io/docs/start/\n(记得安装kubectl,可以自单独安装，也可以通过minikube下载kubectl)\n打开控制面板\nminikube dashboard 准备服务 服务代码 来个传统的http-server\nfunc rawHttpServer() { http.HandleFunc(\u0026#34;/hello\u0026#34;, func(w http.ResponseWriter, r *http.Request) { _, _ = w.Write([]byte(\u0026#34;hello world\u0026#34;)) }) if err := http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil); err != nil { fmt.Println(err) os.Exit(1) } } 服务编译打包 1.编写DockerFile\nFROM golang:alpine AS builder RUN mkdir /app COPY . /app WORKDIR /app/httpdemo RUN go build -o httpdemo FROM alpine:3.18.2 WORKDIR /runtime COPY --from=builder /app/httpdemo/httpdemo /runtime/httpdemo ENTRYPOINT [\u0026#34;./httpdemo\u0026#34;] 2.打包镜像 特别注意，因为选择本地打包，在打包前需要将minikube的docker环境变量设置好\n# 此命令将minikube的docker-env在当前session中设置 eval $(minikube docker-env) # 打包httpdemo:v1 docker build -t httpdemo:v1 -f httpdemo/Dockerfile . 服务部署 1.创建Deployment(启动pod)\n因为Deployment默认是会从hub上拉镜像，因此需要将imagePullPolicy配置从ifNotPresent改为Never\nkubectl create deployment http-demo --image=httpdemo:v1 --image-pull-policy=Never btw, 可以通过-o选项生成当前deployment配置文件\nkubectl create deployment http-demo --image=httpdemo:v1 -o yaml # 在生成的httpdemo.yaml中修改imagePullPolicy # 重新根据配置加载deployment kubectl apply -f httpdemo.yaml 2.创建service kubernetes默认pod只能在其虚拟内网中通信, 若要和外网通信需要建立service ```shell kubectl expose deployment http-demo --type=LoadBalancer --port=8080,8081 minikube service http-demo 3.打开页面，可以正常访问服务\n","permalink":"https://excaburay.github.io/posts/kubernetesminikube%E9%83%A8%E7%BD%B2%E6%9C%8D%E5%8A%A1/","summary":"将本地的http服务，打包编译，并在minikube上部署运行","title":"kubernetes(minikube)部署服务"},{"content":"简介 ratelimit是uber提供的一个极简的漏桶限流实现，主打一个简约轻量，只提供一个接口来实现带阻塞的限流能力。\nimport \u0026#34;go.uber.org/ratelimit\u0026#34; 漏桶限流的方案，即抽象一个类似漏桶的概念，请求只能按照恒定的速率从桶中“漏”过。其实核心是控制流速，桶不桶的并不重要；从uber对此的实现也能看出，核心是把握速率即单位时间内放行的流量(请求个数)。计数限流、漏桶限流、令牌桶限流这三种方案相关的介绍已经有很多了，在此就不过多赘述了。\n源码分析 代码结构 New func New(rate int, opts ...Option) Limiter { return newAtomicInt64Based(rate, opts...) } rate即为最小单位时间通过的请求个数(即流速)；option包含三种可选配置：可指定clock实现，slack松弛区间，perOption最小时间单位 Limiter定义 type Limiter interface { // Take should block to make sure that the RPS is met. Take() time.Time } 就只定义了一个Take方法来实现限流，返回当前通过限流逻辑的时间 ratelimit内部保留了三种limiter实现: 最基础的limiter_mutexbased，改进为原子锁的limiter_atomic，简化数据结构后的limiter_atomic_int64。真正投入使用的是最后一种limiter_atomic_int64。 代码实现 感谢uber将着三种实现都保留在了此项目中，使得我们有机会从中感受到它每一次的优化了什么，背后的思考是什么。接下来让我们快速分析这三个实现版本，每个版本就一个核心方法，代码量很小，\nlimiter_mutexbased // Take calls is on average per/rate. func (t *mutexLimiter) Take() time.Time { t.Lock() defer t.Unlock() now := t.clock.Now() // 如果是第一次请求，直接放行 if t.last.IsZero() { t.last = now return t.last } // sleepFor 计算的是处理当前请求我们需要等待多长时间，其值通过单个请求的流速以及上一个请求通过的时间来决定。 t.sleepFor += t.perRequest - now.Sub(t.last) // 在一些极端场景下，我们不能允许sleepFor成为一个很大的负值，否则那将代表后续系统可能允许极高的RPS通过。（这里的t.maxSlack是个负数） if t.sleepFor \u0026lt; t.maxSlack { t.sleepFor = t.maxSlack } // 如果sleepFor是大于0的，那么我们就需要等待 if t.sleepFor \u0026gt; 0 { t.clock.Sleep(t.sleepFor) t.last = now.Add(t.sleepFor) t.sleepFor = 0 } else { t.last = now } return t.last } 源码的英文注释其实已经讲得很明白了，希望我写的中文不会反而增加了理解难度。 这里核心理解sleepFor这样一个结构就够了，逻辑其实很简单，都在注释里了。 limiter_atomic func (t *atomicLimiter) Take() time.Time { var ( newState state taken bool interval time.Duration ) // 真正互斥的操作是CompareAndSwapPointer，只有替换成功才代表处理了当前这个请求，因此外围会增加一个for循环；这个for循环内大部分逻辑都是处于并发中的。 for !taken { now := t.clock.Now() previousStatePointer := atomic.LoadPointer(\u0026amp;t.state) oldState := (*state)(previousStatePointer) newState = state{ last: now, sleepFor: oldState.sleepFor, } // 对第一次请求，直接放行(并发场景就算走进了这个分支里，咱也不知自己是不是真正的第一个请求，所以还得通过token判断) if oldState.last.IsZero() { taken = atomic.CompareAndSwapPointer(\u0026amp;t.state, previousStatePointer, unsafe.Pointer(\u0026amp;newState)) continue } // 计算需要等待的时间 newState.sleepFor += t.perRequest - now.Sub(oldState.last) // slack处理 if newState.sleepFor \u0026lt; t.maxSlack { newState.sleepFor = t.maxSlack } // sleepFor大于零则记录需要等待的时间，睡眠的时间 if newState.sleepFor \u0026gt; 0 { newState.last = newState.last.Add(newState.sleepFor) interval, newState.sleepFor = newState.sleepFor, 0 } taken = atomic.CompareAndSwapPointer(\u0026amp;t.state, previousStatePointer, unsafe.Pointer(\u0026amp;newState)) } t.clock.Sleep(interval) return newState.last } 只有CompareAndSwapPointer处才是资源互斥的，其外围都是并发场景，因此要增加for循环直到compare成功才代表处理了当前的请求哈 每次调用时，将上一次通过时间和当前等待时间(slack松弛度)作为state状态以原子锁维护。这里的每次newState.sleepFor隐含了继承上次未使用到的松弛度。 limiter_atomic_int64 func (t *atomicInt64Limiter) Take() time.Time { var ( newTimeOfNextPermissionIssue int64 now int64 ) for { now = t.clock.Now().UnixNano() timeOfNextPermissionIssue := atomic.LoadInt64(\u0026amp;t.state) switch { case timeOfNextPermissionIssue == 0 || (t.maxSlack == 0 \u0026amp;\u0026amp; now-timeOfNextPermissionIssue \u0026gt; int64(t.perRequest)): // if this is our first call or t.maxSlack == 0 we need to shrink issue time to now newTimeOfNextPermissionIssue = now case t.maxSlack \u0026gt; 0 \u0026amp;\u0026amp; now-timeOfNextPermissionIssue \u0026gt; int64(t.maxSlack): // a lot of nanoseconds passed since the last Take call // we will limit max accumulated time to maxSlack newTimeOfNextPermissionIssue = now - int64(t.maxSlack) default: // calculate the time at which our permission was issued newTimeOfNextPermissionIssue = timeOfNextPermissionIssue + int64(t.perRequest) } if atomic.CompareAndSwapInt64(\u0026amp;t.state, timeOfNextPermissionIssue, newTimeOfNextPermissionIssue) { break } } sleepDuration := time.Duration(newTimeOfNextPermissionIssue - now) if sleepDuration \u0026gt; 0 { t.clock.Sleep(sleepDuration) return time.Unix(0, newTimeOfNextPermissionIssue) } // return now if we don\u0026#39;t sleep as atomicLimiter does return time.Unix(0, now) } 不愧是最终的实现版，果然是最简洁的。首先将逻辑中的条件进行整合，直接改成switch case的方式，可谓是一目了然。 其次，保持的状态只需要简化成目标时间的时间戳就可以了，一个int64足矣，不可不谓之简约。 newTimeOfNext通过直接累加一个perRequest的方式，使得累计的slack松弛量直接保留在了newTimeOfNext和now的时间差中 总结 本库使用方面\n需要阻塞流量，且限流速率基本固定无需调整的场景，直接使用ratelimit简单又省事； maxSlack请一定要设置(或设置为WithoutSlack)，否则可能会出现极高流量击穿的场景； 代码设计方面 优化互斥逻辑，有一条大路即使用原子锁代替互斥锁。其优化的本质是减少了互斥空间内的操作，尽可能提高了并发度。而使用原子锁场景基本都是细化互斥资源到指定对象，就如此项目方案一和二之间的优化； 老生常谈的基于option的构造方法，有些对象都可以抽出来直接让使用方自己实现； 分支逻辑的优化，能抽出公共的逻辑就一定要抽出，尽可能让分支的路口和尽头都一目了然； ","permalink":"https://excaburay.github.io/posts/ratelimit/","summary":"ratelimit是uber提供的一个极简的漏桶限流实现，主打一个简约轻量。","title":"限流--uber-ratelimit"}]